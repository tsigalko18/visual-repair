%% !TEX root =  paper.tex
\section{Approach}\label{sec:approach}

The goal of our approach is to find potential fixes that can repair a broken web test that used to work correctly on a version $V$ of the AUT, and that now breaks when applied on a subsequent version $V+n$ (with usually $n=1$).

The focus of our technique is to repair \textit{locators}, that represent the main source of breakage.
Our technique can detect and correct locator problems that pertain to the breakage scenarios described in \autoref{sec:breakage-scenarios}.
In a nutshell, we capture the execution trace of each test statement for a version $V$ and use it to assert the correctness of the test execution and repair it for a subsequent version $V+n$. While for certain breakages, we automatically repair them, we also warn the developer of potential inconsistencies or breakages, and creates potential candidate repairs that fix them. \andrea{suggest vs repair}

\begin{figure}[t]
\centering
%\fbox{
\includegraphics[trim={0.2cm 6.5cm 17cm 0.2cm},clip,scale=0.28]{images/approach-bigger}
%}
\caption{Overview of our approach. Inputs and outputs are shown as parallelograms, whereas the proposed approach is represented as rounded rectangles.}
\label{approach}
\end{figure}

\autoref{approach} illustrates the usage scenario for our approach in a real-world testing environment. 
First, given a stable version of the web application $V$ along with its working test suite $TS$ (i.e., in which all tests pass)~\ding{182}, a tester would run $TS$ by means of the first module of the presented approach~\ding{183}. Such a module collects, for each test, a variety of information (e.g., screenshots, DOMs)~\ding{184}. 
Then, as the application $V$ evolves into a new version $V'$ ~\ding{185}, a tester may wish to use $TS$ to check if regressions have occurred. Here, the tester uses the second module of our approach~\ding{186} which runs each test case of the the test suite $TS$ against the new version $V'$, and makes use of the information about the previous execution traces to ``visually'' validate the correctness of each test statement, and eventually attempt to repair locator breakages at runtime in an \textit{online mode}. At the end of the process, the approach outputs the new ``visually'' validated (and eventually repaired) test suite $TS'$ that works on $V'$, together with report information. 
The developer/tester can then manually analyze the report along with repairs that were automatically performed as well as suggested repairs to create an evolved test suite $TS'$. The test suite $TS'$ represents a working test suite for the version $V'$ which can be used in the same way when $V'$ evolves. 
The manual effort required is potentially significantly reduced in comparison to a user carefully verifying each executing test and manually searching for fixes as breakages occur. %
We now detail each step of our approach. 

\subsection{Execution Trace Collection}
%
In the first part of our approach, we capture a model of the  runtime execution of the test cases. 
The test model is a sequence of test states, where each test state captures the DOM and visual information associated with each test statement of each test case. 

%While most of the DOM information could be collected statically, the visual appearance of the rendered elements may change during the application execution and some elements may be not visible until specific events occur. For this reason, we need to capture the visual information at runtime, while the test suite is executing. 

%To this aim, the first module of \tool takes as input a web application along with its accompanying test suite, and runs each test case to collect both DOM and visual information associated to each test statement, hence creating a test model.  %\andrea{I haven't detailed this part by means of an algorithm as references are provided}

%We used and adapted the publicly available version of \textsc{PESTO}~\cite{2014-Stocco-SCAM}, a tool that uses aspect-oriented programming~\cite{aop} -- to intercept all Selenium WebDriver method calls (e.g., \texttt{click()}, \texttt{sendKeys()}, etc) using properly defined join-points. 

%We use aspect-oriented programming~\cite{aop} to intercept all Selenium WebDriver method calls (e.g., \texttt{click()}, \texttt{sendKeys()}, etc) using properly defined join-points. When a given join-point matches, advice methods store the test state \textit{before} and \textit{after} the statement's execution. 


\begin{figure*}[t]
\centering
%\fbox{
\includegraphics[trim={0.3cm 17cm 0.4cm 0.3cm},clip,scale=0.44]{images/cv}
%}
\caption{Computer vision pipeline for robust web element detection.}
\label{fig:cv}
\end{figure*}

The test state encompasses the following DOM-related information: \textit{(d1)}~the complete HTML page, \textit{(d2)}~the DOM, \textit{(d3)}~the XPath of the web element the test statement interacted with and \textit{(d4)}~all its HTML attributes. The collected visual information concern: \textit{(v1)}~the screenshots, \textit{(v2)}~the coordinates and size of the web element's bounding box, and \textit{(v3)}~a visual locator for it. A visual locator is the portion of the rendered web page that uniquely identifies such web element on the screen. (Note that, as explained in~\cite{2014-Stocco-SCAM,2015-Leotta-SAC}, a visual locator is not always the precise crop of the web element's bounding box. There are cases in which a larger crop -- taking into account the web element's visual context --  is necessary in order to visually differentiate it from other visually similar web elements appearing on the page, as the case of a list of input text fields in a form).
%
We refer to this model of the runtime execution of the tests as \textit{dynamic visual execution trace}.

\subsection{Visual-Augmented Test Suite Runner}

\autoref{algo:alg1} illustrates the main procedure of our algorithm for the visual-augmented execution of test cases. The procedure takes as input the execution trace $EX$ of a test case $T$ on version $V$ of the web application, the test case $T$, and the URL $U$ of the web application $V'$. The outputs are a test $T'$, and a list of verified/repaired statements. 

\noindent
\textbf{Initialization.} 
The initial part involves loading the previously saved trace execution information of the test $T$ on the reference version $V$, and loading the new version $V'$ by means of Selenium WebDriver (Lines~1--2). 

\noindent
\textbf{Visual-Augmented Execution.}
Such information is used to ``visually'' validate each statement $st_i$ of $T$, when executed on $V'$ (main loop Lines~4--36). The validation proceeds as follows. First, the DOM-based locator utilized by the test statement is extracted from $st_i$, along with the visual locator (e.g., an image) and the DOM information associated to the trace of $st_i$ in $V$  (Lines~5--7). Then, the \texttt{driver} instance is used to query the DOM of $V'$ to observe if the locator returns a web element (Line~8). 

\input{algo1}

\noindent
\textbf{Detecting and Repairing non-selection problems.}
If no elements are returned, we treat it as a non-selection, and $st_i$ will break in $V'$, which we attempt to repair through a series of countermeasures. The first heuristic tries to search for the web element \textit{visually} on the same state. The \texttt{visualSearch} function (Line~11) uses advanced computer vision algorithms to retrieve the target web element visually by  matching the visual locator captured in $V$ on the current screenshot of $V'$. The DOM information is also used to guide the search, and filter out potential outliers or visual false positives (such as visual duplicates). If a result is found, the locator of $st_i$ is updated, and the corrected statement saved in the list of repairs (Line~21--22). Then, $st_i$ is executed, and saved as a statement of the new test case $T'$ (Lines~34--35), before proceeding to the next statement.

If the visual search on the same state fails, then our approach assumes that the element no longer exists on the current state. We consider this a broken workflow and trigger a local exploration of the application state space (procedure \textsc{localCrawling} of Line~13) in order to find the element in the neighbouring states. In each new state discovered by the exploration, we attempt the \textsc{visualSearch} procedure to locate the element. If a match is found in at least one of those states, a new statement to reach that state (i.e, page) is created, with the corresponding DOM locator, and a default \texttt{click} action, and added before $st_i$ in the the list of repairs (Lines~17--18). (We currently do not support the creation of general purpose statements, such as the ones that need input data).

On the contrary, if a match is not found, i.e. we cannot locate the element through local crawl, we attempt to repair the broken workflow by deleting the $st_i$ and proceeding to the next test statement (Line~15).

\noindent
\textbf{Detecting and Repairing mis-selection problems.}
If a web element was returned by the initial DOM-based locator, our approach asserts the correctness of the selection by using the previously collected visual and DOM information (Lines~25--33). Additionally, in case of assertions, if the GUI textual information of the web element has changed, a new statement with the potentially corrected assertion is created and saved in the list of repairs (Lines~29--33). \andrea{suggestion?}
Note that we only suggest a repair to the assertion statements but do not attempt to repair them automatically since only a human tester upon manual inspection can ascertain whether a new value in GUI reflects the intended application behaviour.
Thus, the execution of $st_i$ will likely raise an \texttt{AssertionError} for the tester to inspect, for which a candidate repair has been automatically created.

\noindent
\textbf{Outputs.}
If \autoref{algo:alg1} terminates, our approach was able to either correct all the statements of $T$ or provide suggestions for it. 
% in the new version $V'$. 
 If $T = T'$ no regressions have occurred, otherwise the list of repairs is returned.
If \autoref{algo:alg1} stops prematurely, then one of the statements executed by the function \textsc{executeStatement} triggered an action that could not be performed or an incorrect locator was retrieved. The tester must then intervene to manually correct such unfortunate cases.

In the following sections we describe the core components of our algorithm, that is the \textsc{visualSearch} and \textsc{localCrawling} procedures that underlie at the functioning of our approach.

\subsection{Visual Search of Web Elements}

As described in \autoref{sec:cv}, matching specific portions of images across different versions of a web application is a challenging task, for which existing computer vision (CV) algorithms perform poorly. 

Thus, the \textsc{visualSearch} adopts a pipeline of CV algorithms, each one devoted to a specific task. The pipeline is graphically illustrated in \autoref{fig:cv}. In the first step, we need to robustly detect the absence/presence of the template image in the screenshot. As anticipated in \autoref{sec:tm}, pure template matching is not adequate. % for this problem. 

\noindent
\textbf{Feature Detection for Template Absence/Presence.}
We adopted two famous feature detection algorithms from the CV literature, SIFT~\cite{Lowe1999,Lowe2004} and FAST~\cite{rosten2005tracking,rosten2008faster}, to detect the key-points from the template image~\textcircled{\raisebox{-0.6pt}{a}}. Through experimentation, we found that these two approaches complement each other well and applying both of them together is beneficial. SIFT performs well mostly for text-based templates whereas FAST can handle the cases where the template represents an ``empty'' text field, as it is specifically designed for corner detection. In our pictorial example~\textcircled{\raisebox{-0.6pt}{a}}, most of the key-points detected by SIFT are in fact nearby the ``Login'' label, whereas FAST detected key-points also in proximity of the corners.
 
Then, descriptors are calculated for each key-point, and the algorithms try to match them onto the new screenshot~\textcircled{\raisebox{-0.6pt}{b}}.
If at least 70\% of key-points are matched across the two images, we can have a certain degree of confidence that the template is present in the image. 

\noindent
\textbf{Template Matching with visual and DOM filtering.}
In the next step, if the feature detection returned true, a pure template matching technique is executed~\textcircled{\raisebox{-0.6pt}{c}}. The performance of template matching oscillate depending on various factors, such as the size, and the threshold being used. For this reason, the templates that do not fall in the region where most of the key-points have been found, are discarded (\textit{visual-based filtering}). If multiple matches are still present, we retrieve the DOM elements corresponding to each match, and we calculate the closest web element that matches the DOM information (\textit{DOM-based filtering}).
Thus, only the closest match is returned (see the green thick rectangle over the ``Login'' button). In brief, the three algorithms operate to find a consensus on the area in which the best match can be found. 

\noindent
\textbf{From GUI to DOM.}
To retrieve the DOM-element corresponding to a specific point of coordinates $(x,y)$, \textsc{visualSearch} queries the browser through a JavaScript command -- \texttt{elementFromPoint(x,y)} -- that returns the DOM element whose bounding box contains \texttt{x} and \texttt{y}. 

%To precisely identify the web element of interest, we need to provide the function with the coordinates of the the \textit{centre} of the bounding box. Otherwise, a DOM ancestor of the searched web element (e.g., the \texttt{form} container), will be erroneously retrieved.

\subsection{Local Crawling for Workflow Repair}

Manually repairing every broken workflow is tedious and frustrating, since even a medium-size web application may contain tens of GUI screens and hundreds of GUI actions. It is hence likely infeasible for a tester to quickly explore this space to choose replacement actions from.

Fortunately, a web crawler can do this automatically. To this end, the \texttt{localCrawling} function integrates \textsc{Crawljax}, a state of the art tool for the automatic crawling of dynamic web applications~\cite{mesbah:tweb12,mesbah:tse12}. We developed a \textsc{Crawljax} plugin that incorporates the \texttt{visualSearch} function (Line~11), so that the crawler can effectively explore the state space of $V'$ looking for a visual match in all the neighbouring states of the current test state (Line~13). As a conservative choice, since the number of DOM states and events can be numerous, we set the crawling depth to one (1). On the one hand, this limits the search capability, potentially missing states in which the elements could be found. On the other hand, this choice keeps the running time acceptable.

\subsection{Implementation}\label{sec:implementation}

We implemented our approach in a tool called \tool, which is publicly available (URL omitted). 
The tool is written in Java, and supports Selenium test suites written in Java. However, our overall approach is more general and applicable to test suites developed using other programming languages or testing frameworks. 
\tool gets as input the path to the test suites, collects the visual execution traces by means of \textsc{PESTO}~\cite{2014-Stocco-SCAM}, runs the visual-augmented detection and repair algorithm using the computer vision libraries available in OpenCV~\cite{}, and \textsc{Crawljax} for the local crawling exploration. 
\tool makes use of the traces to generate potential repairs and generates a list of repaired test cases.







